# pytorchæ•™ç¨‹
## 1.å¸¸ç”¨ç±»
å‰ç½®å·¥ä½œï¼š
* é“¾æ¥ä¸»æœºï¼šssh zhouxingyu@192.168.3.72
* ç¯å¢ƒï¼šconda activate pytorch
**ä½¿ç”¨tensorboardæŸ¥çœ‹å†™å…¥logçš„å‡½æ•°:**
1. æŸ¥çœ‹å‘½ä»¤ï¼š
   tensorboard --logdir="/home/zhangxiaohong/zhouxingyu/demo/machineLearning/logs" --port=6552

   tensorboard --logdir="E:/pythonworksation/MachineLearning/logs" --port=6552ï¼ˆè‡ªå·±çš„ç”µè„‘ï¼‰

2. ï¼ˆæœ¬åœ°cmdï¼‰sshç«¯å£è½¬å‘åˆ°æœ¬åœ°6552ï¼š
   ssh -L 6552:localhost:6552 zhouxingyu@192.168.3.72

æŸ¥çœ‹cudaï¼š
```
# å…¶ä¸­-nåé¢çš„1è¡¨ç¤ºçš„æ˜¯æ¯éš”å¤šå°‘æ—¶é—´ï¼ˆå•ä½æ˜¯sï¼‰åˆ·æ–°ä¸€æ¬¡
watch -n 1 nvidia-smi
# æˆ–è€…
nvidia-smi
```
### 1.1 å‡½æ•°
* dir()ï¼šæŸ¥çœ‹åŒ…/å‡½æ•°
* help():è¯´æ˜
### 1.2 Tensorboardä½¿ç”¨
```python
from PIL import Image
from numpy.distutils.tests.test_npy_pkg_config import simple
from torch.utils.tensorboard import SummaryWriter
import numpy as np

writer = SummaryWriter("logs")
image_path = "/home/zhangxiaohong/zhouxingyu/demo/data/train/ants_image/0013035.jpg"
img_PIL = Image.open(image_path)
img_array = np.array(img_PIL)
# writer.add_image()è¯»å–æ ¼å¼:img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data
writer.add_image("train", img_array, 1, dataformats='HWC')
# eg.fx=x
for i in range(100):
    # åï¼Œyï¼Œx
    writer.add_scalar("fx=x", i, i)
writer.close()

```
**ä½¿ç”¨tensorboardæŸ¥çœ‹å†™å…¥logçš„å‡½æ•°:**
1.  æŸ¥çœ‹å‘½ä»¤ï¼š
tensorboard --logdir="/home/zhangxiaohong/zhouxingyu/demo/python/logs" --port=6552
2.  ï¼ˆæœ¬åœ°cmdï¼‰sshç«¯å£è½¬å‘åˆ°æœ¬åœ°6560ï¼š
ssh -L 6552:localhost:6552 zhouxingyu@192.168.3.72

![image-20241014111420403](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20241014111420403.png)
### 1.3 Teansformçš„ä½¿ç”¨
```python
# å¸¸ç”¨Transform
from PIL import Image
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms

writer = SummaryWriter(log_dir='./logs')
img = Image.open("dataset/train/bees_image/92663402_37f379e57a.jpg")

# è½¬ä¸ºtensorå¯¹è±¡
trans_totensor = transforms.ToTensor()
img_tensor = trans_totensor(img)
# def add_image(
#         self, tag, img_tensor, global_step=None, walltime=None, dataformats="CHW"
#     ):
# img_tensoréœ€è¦(torch.Tensor, numpy.ndarray, or string/blobname)
writer.add_image("To tensor", img_tensor)
writer.close()

```
**å¸¸è§çš„Transformç”¨æ³•ï¼š**

1. transforms.Normalize(mean=[],std=[])ï¼šoutput[channel] = (input[channel] - mean[channel]) / std[channel]
å®ç°äº†**è¾“å…¥æ ‡å‡†åŒ–**ï¼Œå°†æ¯ä¸ªé€šé“çš„å€¼è°ƒæ•´åˆ°åˆ†å¸ƒå‡å€¼ä¸º0ï¼Œæ–¹å·®(æ ‡å‡†å·®)ä¸º1 çš„èŒƒå›´å†…ã€‚
è¾“å‡ºèŒƒå›´ä¸º[-1,1]
```python
# æä¾›ä¸‰ä¸ªå‡å€¼ä¸‰ä¸ªæ ‡å‡†å·®
# output[channel] = (input[channel] - mean[channel]) / std[channel]
# meanå‡å€¼ï¼Œä¸€èˆ¬å–[0.485, 0.456, 0.406]ï¼ˆå¤§é‡è‡ªç„¶å›¾ç‰‡RGBçš„å¹³å‡å€¼ï¼‰
# stdæ ‡å‡†å·®ï¼Œå¸¸ç”¨ä¸º[0.229, 0.224, 0.225]ï¼ˆè‡ªç„¶å›¾ç‰‡çš„å…¸å‹æ ‡å‡†å·®ï¼‰
trans_norm = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
img_norm = trans_norm(img_tensor)
```
æ ‡å‡†åŒ–ç»“æœï¼š

![image-20241015104215595](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20241015104215595.png)

2. resize_transform = transforms.Resize(size,interpolation,max_size,antialias)
å®ç°**ç¼©æ”¾**å‚æ•°ï¼šsizeï¼Œæ’å€¼æ–¹æ³•ï¼Œæœ€é•¿è¾¹ï¼Œæ˜¯å¦æŠ—é”¯é½¿
æä¾›çš„æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œåˆ™ä¼šæ ¹æ®å›¾åƒçš„çŸ­è¾¹å°†å…¶ç¼©æ”¾åˆ°è¿™ä¸ªå¤§å°ï¼Œé•¿è¾¹åˆ™æ ¹æ®åŸå§‹æ¯”ä¾‹è‡ªåŠ¨è°ƒæ•´
å¦‚æœæä¾›çš„æ˜¯å…ƒç»„ï¼ˆh,w)ï¼Œå›¾åƒç›´æ¥è¢«ç¼©æ”¾ä¸ºæŒ‡å®šé«˜åº¦hå’Œå®½åº¦w
```python
from PIL import Image
from torchvision import transforms

img = Image.open('path_to_image.jpg')  # æ‰“å¼€å›¾åƒ
resize_transform = transforms.Resize((128, 128))  # å®šä¹‰ Resize å˜æ¢
img_resized = resize_transform(img)  # åº”ç”¨å˜æ¢
img_resized.show()  # æ˜¾ç¤ºè°ƒæ•´åçš„å›¾åƒ

```

3. transforms.RandomCrop(size,padding,pad_if_needed,fill,padding_mode)
å®ç°**éšæœºè£å‰ª**ï¼Œå‚æ•°:
size:intè¡¨ç¤ºæ­£æ–¹å½¢ï¼Œï¼ˆhï¼Œwï¼‰æ˜¯é«˜å’Œå®½
å¯é€‰å¡«å……
æ˜¯æˆ–è‡ªåŠ¨å¡«å……ï¼ˆå›¾åƒå°äºæ‰€éœ€è£å‰ªå¤§å°ï¼‰
å¡«å……çš„åƒç´ å€¼
å¡«å……çš„ç±»å‹
4. torchvision.transforms.Compose([])
å¯å°†å¤šä¸ªå›¾åƒè½¬æ¢æ“ä½œè”ç«‹èµ·æ¥ï¼Œæ ¹æ®æ•°ç»„çš„é¡ºåºæ‰§è¡Œæ¯ä¸ªå˜æ¢
``` python
dataset_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((256, 256)),  # å…ˆè°ƒæ•´å›¾åƒå¤§å°
    torchvision.transforms.RandomHorizontalFlip(),  # éšæœºæ°´å¹³ç¿»è½¬
    torchvision.transforms.ToTensor(),  # è½¬æ¢ä¸º Tensor
    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # å½’ä¸€åŒ–
])
```
#### 1.3.1 tensoræ•°æ®ç±»å‹
å¤šç»´æ•°ç»„ï¼Œå¯ç”¨Numpy/åˆ—è¡¨/tensorè½¬æ¢
```python
import torch
tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])
print(tensor.shape)  # è¾“å‡º torch.Size([2, 3])
np_array = np.array([1, 2, 3])
tensor_from_numpy = torch.tensor(np_array)  # ä¼šè‡ªåŠ¨è½¬æ¢ä¸º float32 ç±»å‹
original_tensor = torch.tensor([1.0, 2.0, 3.0])
new_tensor = original_tensor.float()  # è½¬æ¢ä¸º float32 ç±»å‹
```
**å¸¸è§çš„tensoræ•°æ®ç±»å‹ï¼š**
* torch.float32 æˆ– torch.float
``` python 
tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float64)
```
* int32 æˆ– int
``` python
tensor = torch.tensor([1, 2, 3], dtype=torch.int32)
```
**tensoræ“ä½œ**
``` python
# åŠ æ³•
tensor1 = torch.tensor([1.0, 2.0, 3.0])
tensor2 = torch.tensor([4.0, 5.0, 6.0])
sum_tensor = tensor1 + tensor2  # ç»“æœ tensor([5.0, 7.0, 9.0])
# ä¹˜æ³•
x = torch.tensor([1, 2, 3])
y = torch.tensor([4, 5, 6])
print(x * y)  # è¾“å‡º tensor([4, 10, 18])
print(torch.mul(x, y))  # è¾“å‡º tensor([4, 10, 18])
# çŸ©é˜µä¹˜æ³•
x = torch.tensor([[1, 2], [3, 4]])
y = torch.tensor([[5, 6], [7, 8]])
print(torch.matmul(x, y))  # è¾“å‡º tensor([[19, 22], [43, 50]])
print(x @ y)  # ç»“æœç›¸åŒ

# æ‹¼æ¥
x = torch.tensor([[1, 2], [3, 4], [5, 6]])
y = torch.tensor([[7, 8], [9, 10], [11, 12]])
z = torch.cat([x, y], dim=0)#ç¬¬0ç»´æ‹¼æ¥ï¼ˆæ ·æœ¬æ•°é‡ï¼‰
print(z)
#ç»“æœä¸ºï¼štensor([[ 1,  2],
#        [ 3,  4],
#        [ 5,  6],
#        [ 7,  8],
#        [ 9, 10],
#        [11, 12]])
z = torch.cat([x, y], dim=1)#ç¬¬1ç»´æ‹¼æ¥ï¼ˆæ ·æœ¬ç‰¹å¾ï¼‰
print(z)
#ç»“æœä¸º
#tensor([[ 1,  2,  7,  8],
#        [ 3,  4,  9, 10],
#        [ 5,  6, 11, 12]])

# è°ƒæ•´å¤§å°
x = torch.tensor([[1, 2], [3, 4]])
print(x.reshape(4))  # è¾“å‡º tensor([1, 2, 3, 4])
# ç»´åº¦å˜åŒ–
x = torch.tensor([[[1], [2], [3]]])
print(x.squeeze())  # è¾“å‡º tensor([1, 2, 3])

x = torch.tensor([1, 2, 3])
print(x.unsqueeze(0))  # è¾“å‡º tensor([[1, 2, 3]])
# è½¬ç½®
x = torch.tensor([[1, 2], [3, 4]])
# ç¬¬0ä¸ªç»´åº¦å’Œç¬¬1ä¸ªç»´åº¦äº¤æ¢Â·	
print(x.transpose(0, 1))  # è¾“å‡º tensor([[1, 3], [2, 4]])
# tensoråªæœ‰ä¸€ä¸ªå…ƒç´ æ—¶è·å–
x = torch.tensor([3.14])
print(x.item())  # è¾“å‡º 3.14

```
### 1.4 torchvisionä¸­æ•°æ®é›†çš„ä½¿ç”¨

```python
# å¸¸ç”¨Transform
from PIL import Image
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms

writer = SummaryWriter(log_dir='./logs')# å½“å‰ç›®å½•ä¸‹logæ–‡ä»¶å¤¹
img = Image.open("dataset/train/bees_image/92663402_37f379e57a.jpg")

# è½¬ä¸ºtensorå¯¹è±¡
trans_totensor = transforms.ToTensor()
img_tensor = trans_totensor(img)
# def add_image(
#         self, tag, img_tensor, global_step=None, walltime=None, dataformats="CHW"
#     ):
# img_tensoréœ€è¦(torch.Tensor, numpy.ndarray, or string/blobname)
writer.add_image("To tensor", img_tensor)
writer.close()

```
**å¸¸è§çš„Transformç”¨æ³•ï¼š

### 1.3 Torchvisionæ•°æ®é›†çš„ä½¿ç”¨
```python
writer = SummaryWriter(log_dir="log")
for i in range(10):
    img, target = test_set[i]
    writer.add_image('img', img, i)
    print(i, " ", img, " ", target)
print("done")
writer.close()
```
### 1.5 dataloaderçš„ä½¿ç”¨
dataloaderæ˜¯å¤„ç†å’ŒåŠ è½½æ•°æ®çš„å·¥å…·ã€‚å®ƒæä¾›äº†å°†æ•°æ®é›†åˆ†æ‰¹åŠ è½½åˆ°æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒæˆ–æµ‹è¯•çš„åŠŸèƒ½ï¼Œæ”¯æŒæ‰¹å¤„ç†ã€æ‰“ä¹±é¡ºåºï¼ˆshuffleï¼‰ã€å¤šçº¿ç¨‹è¯»å–ç­‰
1. åˆå§‹åŒ–ï¼š
```python
test_data = torchvision.datasets.CIFAR10("./data", train=False, transform=torchvision.transforms.ToTensor(),
                                         download=True)
                                         # batch_sizeï¼šæ¯æ¬¡ä»æ•°æ®é›†ä¸­# # è¯»å–çš„æ ·æœ¬æ•°é‡ï¼Œä¸€ä¸ªbatchçš„å¤§å°
# shuffleï¼šæ˜¯å¦åœ¨æ¯ä¸ª epoch å¼€å§‹æ—¶æ‰“ä¹±æ•°æ®é›†ä¸­çš„æ ·æœ¬é¡ºåº
# num_workersï¼šä½¿ç”¨å¤šå°‘ä¸ªå­è¿›ç¨‹æ¥å¹¶è¡ŒåŠ è½½æ•°æ®
# pin_memoryï¼šæ˜¯å¦å°†åŠ è½½çš„æ•°æ®å¤åˆ¶åˆ° CUDA å›ºå®šå†…å­˜ä¸­
# drop_lastï¼šå¦‚æœtrueï¼Œåœ¨æ•°æ®é›†ä¸èƒ½è¢«æ•´é™¤æ—¶ï¼Œä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„batch
test_loader = DataLoader(dataset=test_data, batch_size=4, shuffle=True, num_workers=0)
```
2. è¯»å–
```python
for data in test_loader:
    images, targets = data
    print(images.shape, targets.shape)
    # torch.Size([4, 3, 32, 32]) è¡¨ç¤ºå››å¼ å›¾ç‰‡ï¼Œæ¯ä¸ªå›¾ç‰‡3ä¸ªé€šé“ï¼ˆRGBï¼‰ï¼Œå¤§å°æ˜¯32x32
    # torch.Size([4]) è¡¨ç¤º4ä¸ªæ ‡ç­¾
    print(targets)
```
3. æµ‹è¯•
```python
test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False, num_workers=0)# 64ä¸ªä¸€ç»„


writer = SummaryWriter(log_dir='./logs')
for epoch in range(2):
    step = 0
    for data in test_loader:
        images, labels = data
        writer.add_images("Epoch{}".format(epoch), images, step)
        step += 1

writer.close()
```

![image-20241015211353698](C:\Users\86151\Desktop\img\image-20241015211353698.png)

## 2.ç¥ç»ç½‘ç»œæ­å»º(å·ç§¯)
### 2.1 ç»“æ„
**1. è¾“å…¥å±‚**
**2. éšè—å±‚**
    2.1 å·ç§¯å±‚ï¼ˆConv2dï¼‰ï¼šä½¿ç”¨å·ç§¯è¿ç®—æå–è¾“å…¥æ•°æ®çš„å±€éƒ¨ç‰¹å¾ã€‚é€šè¿‡å¤šä¸ªå·ç§¯æ ¸ï¼ˆæ»¤æ³¢å™¨ï¼‰å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆç‰¹å¾å›¾ã€‚ï¼ˆå‡ ä¸ªå·ç§¯æ ¸å‡ ä¸ªç‰¹å¾å›¾ï¼‰
    2.2 æ± åŒ–å±‚ï¼ˆMaxPool2dã€AvgPool2dï¼‰ï¼šä½¿ç”¨å·ç§¯è¿ç®—æå–è¾“å…¥æ•°æ®çš„å±€éƒ¨ç‰¹å¾ã€‚é€šè¿‡å¤šä¸ªå·ç§¯æ ¸ï¼ˆæ»¤æ³¢å™¨ï¼‰å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆç‰¹å¾å›¾ã€‚
    2.3 å…¨è¿æ¥å±‚ï¼ˆLinearï¼‰ï¼šå°†è¾“å…¥ç‰¹å¾ä¸è¾“å‡ºç‰¹å¾è¿›è¡Œçº¿æ€§å˜æ¢ã€‚
    2.4 æ¿€æ´»å±‚ï¼ˆReLUã€Sigmoidã€Tanhï¼‰ï¼šå¼•å…¥éçº¿æ€§ï¼Œå¸®åŠ©æ¨¡å‹å­¦ä¹ å¤æ‚çš„å‡½æ•°ã€‚
**3. æ­£åˆ™åŒ–å±‚**
	3.1 æ‰¹å½’ä¸€åŒ–ï¼ˆBatchNormï¼‰ï¼šåœ¨æ¯ä¸ªå°æ‰¹é‡ä¸­å¯¹æ¿€æ´»å€¼è¿›è¡Œæ ‡å‡†åŒ–ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ã€‚
	3.2 Dropoutï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒï¼Œå‡å°‘è¿‡æ‹Ÿåˆã€‚
** 4.è¾“å‡ºå±‚**
	4.1 å…¨è¿æ¥å±‚ï¼šç”¨äºç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼Œé€šå¸¸ä¸æ¿€æ´»å‡½æ•°ç»“åˆï¼Œå¦‚ softmax ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚
**5.æŸå¤±å±‚**
	5.1 æŸå¤±å‡½æ•°ï¼šè®¡ç®—é¢„æµ‹è¾“å‡ºä¸å®é™…æ ‡ç­¾ä¹‹é—´çš„å·®è·ï¼Œå¦‚äº¤å‰ç†µæŸå¤±ã€å‡æ–¹è¯¯å·®ç­‰ã€‚

### 2.2 å·ç§¯å±‚
1. å·ç§¯æ ¸ï¼šä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œå½“ç„¶è¿™ä¸ªäºŒç»´çŸ©é˜µè¦æ¯”è¾“å…¥å›¾åƒçš„äºŒç»´çŸ©é˜µè¦å°æˆ–ç›¸ç­‰ï¼Œå·ç§¯æ ¸é€šè¿‡åœ¨è¾“å…¥å›¾åƒçš„äºŒç»´çŸ©é˜µä¸Šä¸åœçš„ç§»åŠ¨ï¼Œæ¯ä¸€æ¬¡ç§»åŠ¨éƒ½è¿›è¡Œä¸€æ¬¡ä¹˜ç§¯çš„æ±‚å’Œï¼Œä½œä¸ºæ­¤ä½ç½®çš„å€¼
2.è¾“å‡ºshapeå’Œå·ç§¯å…³ç³»
*  **è¾“å…¥å½¢çŠ¶**ï¼šå‡è®¾è¾“å…¥çš„å½¢çŠ¶ä¸º $ (H_{in}, W_{in}) $ï¼Œå…¶ä¸­ $ H_{in} $ å’Œ $W_{in}$ åˆ†åˆ«æ˜¯è¾“å…¥çš„é«˜åº¦å’Œå®½åº¦ã€‚
* **å·ç§¯æ ¸å½¢çŠ¶**ï¼šå‡è®¾å·ç§¯æ ¸çš„å½¢çŠ¶ä¸º $(H_{k}, W_{k})$ï¼Œå…¶ä¸­ $H_{k}$ å’Œ $W_{k}$ åˆ†åˆ«æ˜¯å·ç§¯æ ¸çš„é«˜åº¦å’Œå®½åº¦ã€‚
* **æ­¥å¹…**ï¼šæ­¥å¹…ä¸º $S$ï¼Œå®ƒå†³å®šäº†å·ç§¯æ ¸æ¯æ¬¡ç§»åŠ¨çš„åƒç´ æ•°ã€‚
* **å¡«å……**ï¼šå¡«å……ä¸º $P$ï¼Œå®ƒæ˜¯åœ¨è¾“å…¥çš„è¾¹ç¼˜æ·»åŠ çš„é¢å¤–åƒç´ å±‚æ•°ã€‚
è¾“å‡ºå½¢çŠ¶ $(H_{out}, W_{out})$ å¯ä»¥é€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—ï¼š
$$
H_{out} = \frac{H_{in} + 2P - H_{k}}{S} + 1
$$

$$
W_{out} = \frac{W_{in} + 2P - W_{k}}{S} + 1
$$
![image-20241016100024518](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20241016100024518.png)
3. conv2då‡½æ•°ï¼š

**ç¡®å®šäº†å·ç§¯æ ¸å’Œè¾“å…¥**
```python
# å·ç§¯å±‚
import torch
import numpy as np
import torch.nn.functional as F

m, n = -8, 8
random_input = torch.tensor(np.random.randint(m, n, size=(5, 5)))
random_input = torch.reshape(random_input, (1, 1, 5, 5))  # 1batch size 1channel
print(random_input)
# å·ç§¯æ ¸
kernel = torch.tensor(np.random.randint(0, 2, size=(3, 3)))
kernel = torch.reshape(kernel, (1, 1, 3, 3))
print(kernel)
# conv2då‡½æ•°(è¾“å…¥ï¼Œå·ç§¯æ ¸ï¼Œåç½®ï¼Œæ­¥å¹…ï¼Œè¾“å…¥è¾¹ç¼˜å¡«å……çš„åƒç´ æ•°)
output = F.conv2d(random_input, kernel, bias=torch.tensor([2]), stride=1, padding=0)
print(output)
print(random_input.shape)# torch.Size([1, 1, 5, 5])
print(output.shape)# torch.Size([1, 1, 3, 3])
```

![image-20241016165755385](pytorchæ•™ç¨‹.assets/image-20241016165755385.png)
eg.å¯¹äº[0ï¼Œ0ï¼Œ0ï¼Œ0]ä¸€æ¬¡å·ç§¯æ“ä½œä¸º-1-3+4-3  +2=-1

**ä¸å®šä¹‰æƒé‡çŸ©é˜µæ—¶ï¼Œä¼šéšæœºåˆå§‹åŒ–**
```python
import torch
import torchvision
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("./data", train=False, transform=torchvision.transforms.ToTensor(),
                                       download=True)
dataloader = DataLoader(dataset, batch_size=64)


class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = torch.nn.Conv2d(3, 6, 3, stride=1, padding=0)
        # è‡ªåŠ¨ç”Ÿæˆæƒé‡çŸ©é˜µ,å¹¶éšæœºåˆå§‹åŒ–è¿™äº›æƒé‡
        # æ¯ä¸ªè¾“å‡ºé€šé“æœ‰ç‹¬ç«‹çš„å·ç§¯æ ¸ï¼Œæ¯ä¸ªå·ç§¯æ ¸çš„å¤§å°æ˜¯3x3x3

    # è¾“å‡ºx
    def forward(self, x):
        x = self.conv1(x)
        return x


net = Net()

for data in dataloader:
    img, label = data
    output = net(img)
    print(img.shape)
    print(output.shape)
    # torch.Size([64, 3, 32, 32])
    # torch.Size([64, 6, 30, 30])

```

### 2.3 æ± åŒ–å±‚

é™ä½ç‰¹å¾å›¾ç»´åº¦ï¼Œå‡å°‘å‚æ•°ï¼Œæ§åˆ¶è¿‡æ‹Ÿåˆå’Œæå–ä¸»è¦ç‰¹å¾ï¼Œå¢å¼ºç‰¹å¾è¡¨ç¤ºçš„å¹³ç§»ä¸å˜æ€§

ä¸»è¦æ˜¯é™ä½è¿ç®—é‡ï¼Œä¹Ÿå¯ä»¥ä¸ä½¿ç”¨

![image-20241030103238052](pytorchæ•™ç¨‹.assets/image-20241030103238052.png)

#### 2.3.1 å¸¸è§çš„æ± åŒ–æ“ä½œï¼š
1. æœ€å¤§æ± åŒ–ï¼šä»å±€éƒ¨åŒºåŸŸä¸­å–æœ€å¤§å€¼ï¼Œé€šå¸¸ç”¨äºä¿ç•™æœ€æ˜¾è‘—çš„ç‰¹å¾ã€‚
$$
H' = \left\lfloor \frac{H + 2p - k}{s} \right\rfloor + 1
$$
è¾“å…¥ç‰¹å¾å›¾HxWï¼Œæ­¥å¹…sï¼Œå¡«å……p
 ```python
   # æ± åŒ–çª—å£çš„å¤§å°ï¼Œstrideæ­¥å¹…ï¼Œpaddingæ˜¯å¦è¡¥0,dilationå·ç§¯æ ¸çš„æ‰©å¼ ç³»æ•°(>1åˆ™æ¯ä¸ªå…ƒç´ ä¹‹é—´æœ‰é—´éš”)
   # ceil_mode: boolè¾“å‡ºå½¢çŠ¶é»˜è®¤flaseå‘ä¸‹å–æ•´ï¼ˆå¦‚æœä¸å¤Ÿä¸€ä¸ªå·ç§¯æ ¸ï¼Œå°±ä¸è¾“å‡ºæ± åŒ–ç»“æœäº†ï¼‰
       def forward(self, input: Tensor):
         return F.max_pool1d(input, self.kernel_size, self.stride,
                             self.padding, self.dilation, ceil_mode=self.ceil_mode,
                             return_indices=self.return_indices)
 ```

```python
import torch
import torch.nn as nn

# åˆ›å»ºä¸€ä¸ª MaxPool2d æ± åŒ–å±‚ï¼Œæ± åŒ–çª—å£å¤§å°ä¸º 2x2
max_pool = nn.MaxPool2d(kernel_size=2)

# å‡è®¾è¾“å…¥æ˜¯ä¸€ä¸ªå¤§å°ä¸º (1, 1, 4, 4) çš„ 4x4 å›¾åƒ
input_tensor = torch.tensor([[[[1., 2., 3., 4.],
                               [5., 6., 7., 8.],
                               [9., 10., 11., 12.],
                               [13., 14., 15., 16.]]]])

# åº”ç”¨æœ€å¤§æ± åŒ–
output = max_pool(input_tensor)

print(output)
# è¾“å‡ºæ˜¯ 2x2ï¼Œæ¯ä¸ªåŒºåŸŸå–æœ€å¤§å€¼
# tensor([[[[ 6.,  8.],
#           [14., 16.]]]])

```
2. å¹³å‡æ± åŒ–ï¼šä»å±€éƒ¨åŒºåŸŸä¸­å–å¹³å‡å€¼ï¼Œå¸¸ç”¨äºå¹³æ»‘ç‰¹å¾å›¾ã€‚
$$
W' = \left\lfloor \frac{W + 2p - k}{s} \right\rfloor + 1
$$
```python
torch.nn.AvgPool2d(kernel_size, stride=None, padding=0)
```
ç¤ºä¾‹ï¼š
```python
avg_pool = nn.AvgPool2d(kernel_size=2)

output = avg_pool(input_tensor)

print(output)
# è¾“å‡ºæ˜¯ 2x2ï¼Œæ¯ä¸ªåŒºåŸŸå–å¹³å‡å€¼
# tensor([[[[ 3.5000,  5.5000],
#           [11.5000, 13.5000]]]])
```
### 2.4 éçº¿æ€§æ¿€æ´»
1. ReLU(): max(0,x)
![image-20241018094913224](pytorchæ•™ç¨‹.assets/image-20241018094913224.png)
```python
  >>> m = nn.ReLU()
  >>> input = torch.randn(2)
  >>> output = m(input)

    #ReLuå‚æ•°æœ‰inplace=True/False
    #True æ›¿æ¢åŸæœ‰è¾“å…¥ jDefault: False

An implementation of CReLU - https://arxiv.org/abs/1603.05201

  >>> m = nn.ReLU()
  >>> input = torch.randn(2).unsqueeze(0)
  >>> output = torch.cat((m(input), m(-input)))
```
2. Sigmoid(x):

![image-20241018095310073](pytorchæ•™ç¨‹.assets/image-20241018095310073.png)

![image-20241018095827146](pytorchæ•™ç¨‹.assets/image-20241018095827146.png)
```python
m = nn.Sigmoid()
input = torch.randn(2)
output = m(input)
```
torchæä¾›çš„sigmoidå‡½æ•°ä¸æ”¯æŒå‚æ•°è°ƒèŠ‚ï¼Œä¸‹é¢æ˜¯è‡ªå®šä¹‰çš„sigmoidå‡½æ•°
```python
import torch
def custom_sigmoid(x, alpha=1.0, beta=0.0):
    return 1 / (1 + torch.exp(-alpha * (x - beta)))

# ä½¿ç”¨ç¤ºä¾‹
x = torch.tensor([0.0, 1.0, 2.0])
output = custom_sigmoid(x, alpha=2.0, beta=1.0)
print(output)
```
### 2.5çº¿æ€§å±‚ä»¥åŠå…¶ä»–å±‚
1. å½’ä¸€åŒ–
å·ç§¯å±‚åï¼Œæ¿€æ´»å‡½æ•°å‰æ·»åŠ ï¼Œå°†æ•°æ®ç¼©æ”¾åˆ°ç‰¹å®šèŒƒå›´ï¼Œå¦‚ [0, 1] æˆ– [-1, 1]ã€‚ç›®çš„æ˜¯ä½¿ç‰¹å¾åœ¨ç›¸åŒçš„å°ºåº¦ä¸Šï¼Œä»è€ŒåŠ å¿«æ”¶æ•›é€Ÿåº¦å’Œæé«˜è®­ç»ƒç¨³å®šæ€§ã€‚
å¯¹è¾“å…¥æ•°æ®çš„å¤„ç†ï¼š
* **è®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼š** åœ¨æ¯ä¸ªbatchå†…ï¼Œè®¡ç®—æ¯ä¸ªé€šé“çš„å‡å€¼å’Œæ–¹å·®

* **æ ‡å‡†åŒ–ï¼š**ä½¿ç”¨è®¡ç®—å‡ºçš„å‡å€¼å’Œæ–¹å·®åšæ ‡å‡†åŒ–ï¼Œä½¿å…¶ç¬¦åˆæ­£æ€åˆ†å¸ƒ

  ![image-20241018110017406](pytorchæ•™ç¨‹.assets/image-20241018110017406.png)
  
* **ç¼©æ”¾å’Œåç§»ï¼ˆaffine=True åˆ™å¯å­¦ä¹ ï¼‰ï¼š**å…è®¸æ¨¡å‹åœ¨æ ‡å‡†åŒ–åè°ƒæ•´è¾“å‡ºçš„åˆ†å¸ƒ

  ![image-20241018110148193](pytorchæ•™ç¨‹.assets/image-20241018110148193.png)
* **ç§»åŠ¨å‡å€¼å’Œæ–¹å·®çš„æ›´æ–°ï¼š**åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒBatchNorm2d ä¼šç»´æŠ¤æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç§»åŠ¨å‡å€¼å’Œæ–¹å·®ï¼Œç”¨äºè¯„ä¼°é˜¶æ®µï¼ˆmodel.eval()ï¼‰æ—¶çš„æ ‡å‡†åŒ–ã€‚

```python
# num_features ä¸ºè¾“å‡ºé€šé“æ•°
self.bn1 = nn.BatchNorm2d(num_features=16)
```
åœ¨è®­ç»ƒæ—¶ï¼ŒBatchNorm2d ä¼šä½¿ç”¨å½“å‰æ‰¹æ¬¡çš„å‡å€¼å’Œæ–¹å·®ï¼Œå¹¶åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼ˆmodel.eval()ï¼‰ï¼Œä½¿ç”¨åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—çš„ç§»åŠ¨å‡å€¼å’Œæ–¹å·®ã€‚
2. æ­£åˆ™åŒ–å±‚

3. çº¿æ€§å±‚

   çº¿æ€§å±‚å…è®¸æ¥å—ä¸€ç»´æˆ–å¤šç»´è¾“å…¥ï¼Œå½“è¾“å…¥æ˜¯å¤šç»´æ—¶ï¼Œå½“è¾“å…¥æ˜¯å¤šç»´å¼ é‡æ—¶ï¼Œ`Linear`å±‚ä¼šå¯¹è¾“å…¥å¼ é‡çš„**æœ€åä¸€ç»´**è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œå¹¶ä¸”ä¸ä¼šæ”¹å˜å…¶ä»–ç»´åº¦çš„ç»“æ„ã€‚
```python
torch.nn.Linear(in_features, # è¾“å…¥çš„ç¥ç»å…ƒä¸ªæ•°
           out_features, # è¾“å‡ºç¥ç»å…ƒä¸ªæ•°
           bias=True # æ˜¯å¦åŒ…å«åç½®
           )
```
![image-20241018115600378](pytorchæ•™ç¨‹.assets/image-20241018115600378.png)
W æ˜¯æ¨¡å‹è¦å­¦ä¹ çš„å‚æ•°
```python
# æŸ¥çœ‹æ¨¡å‹å‚æ•°
for param in model.parameters():
    print(param)
```
ä¾‹å­ï¼š
```python
import torch
import torchvision.datasets as datasets
from sympy.functions.elementary.tests.test_trigonometric import nn
from torch.utils.data import DataLoader
import torchvision.transforms as transforms

dataset = datasets.CIFAR10(root="./data", train=False,
                           transform=transforms.ToTensor(),
                           download=True)


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.linear = nn.Linear(in_features=196608, out_features=10)

    def forward(self, x):
        x = self.linear(x)
        return x


data_loader = DataLoader(dataset, batch_size=64)
for data in data_loader:
    images, targets = data
    print(images.shape)
    output = torch.reshape(images, [1, 1, 1, -1])
    # å±•å¹³ torch.flatten(images)
```

## 3.Sequentialä½¿ç”¨åŠç¥ç»ç½‘ç»œå®æˆ˜
1. CIFAR-10æ•°æ®é›†ç»“æ„
![Structure-of-CIFAR10-quick-model](pytorchæ•™ç¨‹.assets/Structure-of-CIFAR10-quick-model.png)

æ³¨ï¼šFlattenåæ˜¯64\*4\*4ï¼Œå†æ¥ä¸¤ä¸ªçº¿æ€§å±‚

```python
import torch
from torch import nn
from torch.ao.nn.qat import Conv2d
from torch.nn import MaxPool2d, Flatten, Linear, Conv2d


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # self.conv1 = nn.Conv2d(3, 32, 5, padding=2)  # input 3@32x32 output 32@32x32
        # self.maxpool1 = nn.MaxPool2d(2, 2)
        # self.conv2 = nn.Conv2d(32, 32, 5, padding=2)  # input 32@16x16 output 32@16x16
        # self.maxpool2 = nn.MaxPool2d(2, 2)
        # self.conv3 = nn.Conv2d(32, 64, 5, padding=2)  # input 32@8x8 output 64@8x8
        # self.maxpool3 = nn.MaxPool2d(2, 2)
        # self.flatten = nn.Flatten()
        # self.fc1 = nn.Linear(1024, 64)
        # self.fc2 = nn.Linear(64, 10)

        self.model = nn.Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2, 2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2, 2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2, 2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        )

    def forward(self, x):
        # x = self.maxpool1(self.conv1(x))
        # x = self.maxpool2(self.conv2(x))
        # x = self.maxpool3(self.conv3(x))
        # x = self.flatten(x)
        # x = self.fc1(x)
        # x = self.fc2(x)
        x = self.model(x)
        return x


net = Net()
print(net)
input = torch.ones(64, 3, 32, 32)
output = net(input)
print(output.shape)

writer = SummaryWriter(log_dir='./logs')
writer.add_graph(net, input)
writer.close()# tensorboard --logdir="/home/zhangxiaohong/zhouxingyu/demo/python/logs" --port=6552
```

<img src="pytorchæ•™ç¨‹.assets/png.png" alt="png" style="zoom: 25%;" />

æ¨¡å‹è®­ç»ƒï¼š

```python	
import torchvision.datasets
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from CIFAR10QuickModel import *

# æ·»åŠ tensorboard
writer = SummaryWriter('../logs')

# æ•°æ®
train_data = torchvision.datasets.CIFAR10(root='../CIFAR10_datasets', train=True, download=True,
                                          transform=torchvision.transforms.ToTensor())
test_data = torchvision.datasets.CIFAR10(root='../CIFAR10_datasets', train=False, download=True,
                                         transform=torchvision.transforms.ToTensor())
train_data_size = len(train_data)
test_data_size = len(test_data)
print(f'Train data size: {train_data_size}')
print(f'Test data size: {test_data_size}')

train_dataLoader = DataLoader(train_data, batch_size=64, shuffle=True)
test_dataLoader = DataLoader(test_data, batch_size=64, shuffle=True)

# ç¥ç»ç½‘ç»œæ¨¡å‹è®¾ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
net = Net().to(device)
loss_fn = nn.CrossEntropyLoss().to(device)
learning_rate = 1e-2
optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)

# å‚æ•°è®¾ç½®
total_loss = 0
total_train_step = 0
total_test_step = 0
epoch = 20
for i in range(epoch):
    print(f'Epoch {i + 1}---------------------------------------------------------------------')
    train_loss = 0

    net.train()
    for data in train_dataLoader:
        image, labels = data
        image, labels = image.to(device), labels.to(device)
        output = net(image)
        loss = loss_fn(output, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        total_train_step += 1
        if total_train_step % 100 == 0:
            print(f'Loss: {loss.item():.4f},total_train_step: {total_train_step}')
            writer.add_scalar('train_loss', loss.item(), total_train_step)

    # æµ‹è¯•
    total_test_loss = 0
    total_accuracy = 0
    net.eval()
    with torch.no_grad():
        for data in test_dataLoader:
            image, labels = data
            image, labels = image.to(device), labels.to(device)
            output = net(image)
            loss = loss_fn(output, labels)
            total_test_loss += loss.item()

            # æ­£ç¡®ç‡
            accuracy = (output.argmax(dim=1) == labels).sum()
            total_accuracy += accuracy.item()

    print(f'Test Loss: {total_test_loss}')
    print(f'Test Accuracy: {total_accuracy / len(test_data)}')
    writer.add_scalar('test_loss', total_test_loss, i)
    writer.add_scalar('test_accuracy', total_accuracy, i)

    # æ¨¡å‹ä¿å­˜
    torch.save(net.state_dict(), f'../models/net_{i}.path')
writer.close()
```

å‡†ç¡®ç‡ç»Ÿè®¡:

<img src="pytorchæ•™ç¨‹.assets/image-20241023100600945.png" alt="image-20241023100600945" style="zoom: 80%;" />

loss:

![image-20241023100636421](pytorchæ•™ç¨‹.assets/image-20241023100636421.png)

![image-20241023100648961](pytorchæ•™ç¨‹.assets/image-20241023100648961.png)

å›¾åƒæµ‹è¯•ï¼š

```python
import torchvision.transforms
from PIL import Image
from CIFAR10QuickModel import *

classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']


# mage_path = "../img/test7.jpg"


def image_test(image_path):
    # å›¾åƒè½¬æ¢
    image = Image.open(image_path)
    # print(image)
    image = image.convert("RGB")
    transform = torchvision.transforms.Compose(
        [torchvision.transforms.ToTensor(),
         torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
         torchvision.transforms.Resize((32, 32)), ]
    )
    image = transform(image)
    image = torch.reshape(image, (1, 3, 32, 32)).cuda()
    # print(image.shape)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # print(f"Using device: {device}")
    net = Net().to(device)
    net.load_state_dict(torch.load("../models/net_19.path"))
    outputs = net(image).argmax(dim=1)
    print(f"å›¾ç‰‡ç±»å‹ä¸ºï¼š{classes[outputs[0]]}")


if __name__ == '__main__':
    for i in range(8):
        mage_path = f"../img/test{i}.jpg"
        image_test(mage_path)

```



## 4. æŸå¤±å‡½æ•°å’Œåå‘ä¼ æ’­
### 4.1 æŸå¤±å‡½æ•°
**output**ï¼šå®é™…å€¼ï¼›**target**ï¼šçœŸå®å€¼
1. å‡æ–¹è¯¯å·®å‡½æ•°ï¼š
```python 
loss = nn.MSELoss(output, target)# å·®çš„æ–¹/n
```
2. ç»å¯¹è¯¯å·®æŸå¤±ï¼š
``` python
criterion = nn.L1Loss(output, target) # ç›¸å‡å¹³å‡å€¼
```
3. äº¤å‰ç†µæŸå¤±
* äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±
$$
\text{Loss}(y, \hat{y}) = - \left[ y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right]
$$
$y$ æ˜¯çœŸå®æ ‡ç­¾ï¼ˆ0 æˆ– 1ï¼‰ï¼Œ$\hat{y}$æ˜¯æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡ï¼ˆå³è¾“å…¥ä¸ºæ­£ç±»çš„æ¦‚ç‡ï¼‰
* å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±

$$
\text{Loss}(y, \hat{y}) = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)
$$
C æ˜¯ç±»åˆ«æ•°
$y_i$æ˜¯çœŸå®æ ‡ç­¾çš„ç‹¬çƒ­ç¼–ç å½¢å¼ï¼ˆone-hot encodingï¼‰ï¼Œåœ¨ç¬¬ ğ‘– ç±»ä¸º1ï¼Œå…¶ä½™ä¸º0
$\hat{y}$æ˜¯æ¨¡å‹é¢„æµ‹è¯¥ç±»åˆ«çš„æ¦‚ç‡
* ç»„åˆäº†softmaxçš„äº¤å‰ç†µå…¬å¼ï¼š
``` python criterion = nn.CrossEntropyLoss() ```

softmaxå‡½æ•°ï¼š
$$
\hat{y}_i = \frac{e^{z_i}}{\sum_{j=1}^{C} e^{z_j}} \quad \text{for } i = 1, 2, \ldots, C
$$
äº¤å‰ç†µæŸå¤±ï¼š
$$
\text{Loss}(y, z) = - \sum_{i=1}^{C} y_i \log\left( \hat{y}_i \right) = - \sum_{i=1}^{C} y_i \log\left( \frac{e^{z_i}}{\sum_{j=1}^{C} e^{z_j}} \right)
$$

$$
\text{Loss}(y, z) = - \sum_{i=1}^{C} y_i \left( z_i - \log\left( \sum_{j=1}^{C} e^{z_j} \right) \right)
$$

$$
\text{Loss}(y, z) = - \sum_{i=1}^{C} y_i z_i + \log\left( \sum_{j=1}^{C} e^{z_j} \right)
$$
### 4.2 ä¼˜åŒ–å™¨
ä½¿ç”¨SGDä¼˜åŒ–çš„å®ä¾‹
```python
import torch
import torchvision
from torch import nn
from torch.nn import Sequential, Flatten
from torch.utils.data import DataLoader

# æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# åŠ è½½æ•°æ®é›†
dataset = torchvision.datasets.CIFAR10("./data", train=True, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=8, shuffle=True)


# å®šä¹‰æ¨¡å‹
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.model1 = Sequential(
            nn.Conv2d(3, 32, 5, padding=2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 32, 5, padding=2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 5, padding=2),
            nn.MaxPool2d(2),
            Flatten(),
            nn.Linear(1024, 64),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.model1(x)
        return x


net = Net().to(device)  # å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
loss = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.01)

for epoch in range(20):
    running_loss = 0.0
    for data in dataloader:
        image, labels = data
        image, labels = image.to(device), labels.to(device)  # å°†æ•°æ®ç§»åŠ¨åˆ°GPU
        outputs = net(image)
        rel_loss = loss(outputs, labels)
        optimizer.zero_grad()
        rel_loss.backward()
        optimizer.step()
        running_loss += rel_loss.item()
    print(running_loss)
```
1. æ¢¯åº¦ä¸‹é™æ³•
è®¾å®šå­¦ä¹ ç‡n,å‚æ•°æ²¿æ¢¯åº¦çš„åæ–¹å‘ç§»åŠ¨ï¼Œå‡è®¾éœ€è¦æ›´æ–°çš„å‚æ•°ä¸ºwï¼Œæ¢¯åº¦ä¸ºg
   ![image-20241021150331695](pytorchæ•™ç¨‹.assets/image-20241021150331695.png)
(1) æ¢¯åº¦ä¸‹é™æ³•å½¢å¼ï¼ˆä¼ ç»Ÿæ¢¯åº¦ä¸‹é™æ³•)
* BGDï¼šæ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼Œæ¯æ¬¡å‚æ•°æ›´æ–°ä½¿ç”¨**æ‰€æœ‰æ ·æœ¬**
* SGDï¼šéšæœºæ¢¯åº¦ä¸‹é™ï¼Œæ¯æ¬¡å‚æ•°æ›´æ–°ä½¿ç”¨**ä¸€ä¸ªæ ·æœ¬**
* MBGDï¼šå°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼Œæ¯æ¬¡å‚æ•°æ›´æ–°ä½¿ç”¨**å°éƒ¨åˆ†æ•°æ®æ ·æœ¬**
step1ï¼š æ±‚è¯¥æ–¹æ³•æ‰€ä½¿ç”¨çš„æ ·æœ¬çš„lossçš„g
step2ï¼šæ±‚æ¢¯åº¦çš„å¹³å‡å€¼
step3ï¼šæ›´æ–°æƒé‡![image-20241021150331695](pytorchæ•™ç¨‹.assets/image-20241021150331695.png)
2. å¤šç»´æ¢¯åº¦ä¸‹é™æ³•

   å¤šä¸ªå‚æ•°${{X}=[{x_1},{x_2},...,{x_d}]}^T$

   ![image-20241021151919033](pytorchæ•™ç¨‹.assets/image-20241021151919033.png)

3. å¸¦åŠ¨é‡çš„æ¢¯åº¦ä¸‹é™æ³•

![image-20241021153112051](pytorchæ•™ç¨‹.assets/image-20241021153112051.png)

åŠ å¿«æ”¶æ•›ï¼Œå¸®åŠ©è·³å‡ºå±€éƒ¨æœ€å°å€¼

4. Adagradä¼˜åŒ–ç®—æ³•

   å› ä¸ºä¸åŒçš„å‚æ•°æ¢¯åº¦å·®å¼‚å¯èƒ½å¾ˆå¤§ï¼Œå¦‚æœä½¿ç”¨ç›¸åŒçš„å­¦ä¹ ç‡ï¼Œæ•ˆæœä¸æ˜¯å¾ˆå¥½

   æ–¹æ³•ï¼šæ¯ä¸ªå‚æ•°ï¼Œåˆå§‹åŒ–ä¸€ä¸ªç´¯è®¡å¹³æ–¹æ¢¯åº¦r=0ï¼Œæ¯æ¬¡å°†è¯¥å‚æ•°çš„æ¢¯åº¦å¹³æ–¹æ±‚å’Œç´¯åŠ åˆ°rä¸Šï¼š

   ![image-20241021154333489](pytorchæ•™ç¨‹.assets/image-20241021154333489.png)

â€‹	æ›´æ–°å‚æ•°æ—¶ï¼Œå­¦ä¹ ç‡å˜ä¸ºï¼š![image-20241021154417734](pytorchæ•™ç¨‹.assets/image-20241021154417734.png)
â€‹	$\delta$æ˜¯ä¸€ä¸ªæå°å€¼ï¼Œå¯è®¾ä¸º${10^{-10}}$
â€‹	æƒé‡æ›´æ–°ï¼š![image-20241021154854398](pytorchæ•™ç¨‹.assets/image-20241021154854398.png)ï¼Œæ­¤æ—¶å¦‚æœä¸€ä¸ªå‚æ•°çš„æ¢¯åº¦ä¸€ç›´éƒ½å¾ˆå¤§ï¼Œé‚£ä¹ˆå­¦ä¹ ç‡å˜å°ï¼Œé˜²æ­¢æŒ¯	è¡ï¼›å¦‚æœä¸€ä¸ªå‚æ•°çš„æ¢¯åº¦å¾ˆå°ï¼Œå°±è®©å­¦ä¹ ç‡å˜å¤§ï¼Œä½¿å…¶æ›´å¿«æ›´æ–°

5. RMSProp å‡æ–¹æ ¹ä¼ æ’­
    åœ¨Adagradçš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥åœ¨å­¦ä¹ ç‡çš„æ–¹å‘ä¸Šä¼˜åŒ–
    ç´¯è®¡å¹³æ–¹æ¢¯åº¦ï¼š![image-20241021155506302](pytorchæ•™ç¨‹.assets/image-20241021155506302.png)
    æƒé‡æ›´æ–°ï¼š![image-20241021155518236](pytorchæ•™ç¨‹.assets/image-20241021155518236.png)

6. Adam

  	ç´¯è®¡æ¢¯åº¦ï¼š![image-20241021155915555](pytorchæ•™ç¨‹.assets/image-20241021155915555.png)
  	
  	å­¦ä¹ ç‡ï¼Œç´¯è®¡å¹³æ–¹æ¢¯åº¦ï¼š![image-20241021155926083](pytorchæ•™ç¨‹.assets/image-20241021155926083.png)

â€‹	åå·®çº æ­£ï¼š![image-20241021155935656](pytorchæ•™ç¨‹.assets/image-20241021155935656.png)

â€‹	æƒé‡æ›´æ–°ï¼š![image-20241021155945422](pytorchæ•™ç¨‹.assets/image-20241021155945422.png)

```python
def adam(learning_rate, beta1, beta2, epsilon, var, grad, v, r, t):
    v = beta1 * v + (1 - beta1) * grad
    r = beta2 * r + (1 - beta2) * grad * grad
    v_hat = v / (1 - beta1 ** t)
    r_hat = r / (1 - beta2 ** t)
    var = var - learning_rate * (v_hat / (np.sqrt(r_hat) + epsilon))
    return var, v, r
```

## 5.Pythonåº“

### 5.1 è¿›åº¦æ¡ï¼ˆtqdmï¼‰

1.è®¾ç½®è¿›åº¦æ¡æ€»é•¿åº¦,ncolsä¸º0è‡ªåŠ¨æ˜¾ç¤ºå®½åº¦ï¼Œdescæ˜¯æ˜¾ç¤ºåœ¨è¿›åº¦æ¡å‰çš„æè¿°ï¼Œunitæ˜¯å•ä½

```python 
pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc="Valid", unit=" uttr")
```

2. æ›´æ–°è¿›åº¦æ¡
updateé‡Œé¢æ˜¯æ›´æ–°é•¿åº¦
```python
	pbar.update(dataloader.batch_size)
```

3. æ˜¾ç¤ºé™„åŠ ä¿¡æ¯
`set_postfix` ç”¨äºæ›´æ–°è¿›åº¦æ¡çš„åç¼€ä¿¡æ¯ï¼Œé€šå¸¸ç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸€äº›å®æ—¶æŒ‡æ ‡ï¼Œæ¯”å¦‚æŸå¤±ï¼ˆ`loss`ï¼‰å’Œå‡†ç¡®ç‡ï¼ˆ`accuracy`ï¼‰ã€‚æ¯æ¬¡æ›´æ–°æ—¶ï¼Œ`tqdm` ä¼šæ›´æ–°è¿›åº¦æ¡çš„çŠ¶æ€å¹¶æ˜¾ç¤ºè¿™äº›å®æ—¶è®¡ç®—çš„ç»“æœã€‚
```python
    pbar.set_postfix(
        loss=f"{running_loss / (i + 1):.2f}",
        accuracy=f"{running_accuracy / (i + 1):.2f}",
    )

```

## 6. å½’ä¸€åŒ–

#### 6.1 Batch Normalization

è®¡ç®—å‡å€¼å’Œæ–¹å·®æ—¶ï¼Œå®ƒ**åªä¼šè€ƒè™‘å½“å‰æ‰¹æ¬¡ä¸­çš„ç‰¹å®šç‰¹å¾ç»´åº¦**,ä¸ä¼šè·¨æ‰€æœ‰ç‰¹å¾ç»´åº¦è¿›è¡Œè®¡ç®—ã€‚è¾“å…¥ä¸º`(batch_size, seq_len, d_model)`**ï¼ŒBN å¯¹æ¯ä¸€ä¸ªç‰¹å¾ç»´åº¦åˆ†åˆ«è®¡ç®—ä¸€ä¸ªå‡å€¼å’Œæ–¹å·®ï¼Œå…±è®¡ç®— `d_model` ä¸ªå‡å€¼å’Œæ–¹å·®**ã€‚

åœ¨ PyTorch ä¸­ï¼Œ`BatchNorm` ç³»åˆ—å±‚ç”¨äºå®ç°æ‰¹é‡å½’ä¸€åŒ–ã€‚å¸¸ç”¨çš„æ˜¯ `BatchNorm1d`ã€`BatchNorm2d` å’Œ `BatchNorm3d`ï¼Œåˆ†åˆ«ç”¨äº 1Dã€2D å’Œ 3D æ•°æ®ã€‚ä¸‹é¢æ˜¯ `BatchNorm1d` å’Œ `BatchNorm2d` çš„ä½¿ç”¨ç¤ºä¾‹ï¼š

**1. Batch Normalizatoin**

```python
import torch
import torch.nn as nn

# å®šä¹‰ BatchNorm1d å±‚
batch_norm1d = nn.BatchNorm1d(num_features=10)

# åˆ›å»ºè¾“å…¥æ•°æ® (batch_size, num_features)
input_data = torch.randn(32, 10)  # å‡è®¾æœ‰ 32 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ 10 ç»´ç‰¹å¾

# è¿›è¡Œæ‰¹é‡å½’ä¸€åŒ–
output_data = batch_norm1d(input_data)
print(output_data.shape)  # è¾“å‡º: torch.Size([32, 10])
```

** 2. `BatchNorm2d` ç¤ºä¾‹**

`BatchNorm2d` å¸¸ç”¨äº 2D æ•°æ®ï¼Œä¾‹å¦‚å›¾åƒæ•°æ®ã€‚é€šå¸¸åº”ç”¨äºå·ç§¯å±‚è¾“å‡ºï¼Œå®ƒå°†æ¯ä¸ªç‰¹å¾å›¾çš„åƒç´ å€¼è¿›è¡Œå½’ä¸€åŒ–ã€‚

```python
import torch
import torch.nn as nn

# å®šä¹‰ BatchNorm2d å±‚
batch_norm2d = nn.BatchNorm2d(num_features=16)

# åˆ›å»ºè¾“å…¥æ•°æ® (batch_size, num_channels, height, width)
input_data = torch.randn(8, 16, 32, 32)  # å‡è®¾æœ‰ 8 å¼ å›¾åƒï¼Œ16 ä¸ªé€šé“ï¼Œ32x32 å¤§å°

# è¿›è¡Œæ‰¹é‡å½’ä¸€åŒ–
output_data = batch_norm2d(input_data)
print(output_data.shape)  # è¾“å‡º: torch.Size([8, 16, 32, 32])
```

`num_features`ï¼šæŒ‡å®šè¦å½’ä¸€åŒ–çš„ç‰¹å¾æ•°é‡ï¼Œé€šå¸¸ä¸ºé€šé“æ•°ï¼ˆå¯¹äº `BatchNorm2d` å’Œ `BatchNorm3d`ï¼‰ï¼Œæˆ–ç‰¹å¾ç»´åº¦ï¼ˆå¯¹äº `BatchNorm1d`ï¼‰ã€‚

`eps`ï¼šé˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°ï¼Œé»˜è®¤ä¸º `1e-5`ã€‚

`momentum`ï¼šç”¨äºç§»åŠ¨å¹³å‡çš„åŠ¨é‡ï¼Œé»˜è®¤å€¼ä¸º `0.1`ã€‚

`affine`ï¼šæ˜¯å¦å­¦ä¹ å¯å­¦ä¹ çš„ä»¿å°„å‚æ•°ï¼ˆå¯è®­ç»ƒçš„ç¼©æ”¾å’Œå¹³ç§»å‚æ•° `gamma` å’Œ `beta`ï¼‰ï¼Œé»˜è®¤å€¼ä¸º `True`ã€‚

**3.å°† BatchNorm åº”ç”¨äºç¥ç»ç½‘ç»œæ¨¡å‹ **

```python
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(16)  # åœ¨å·ç§¯å±‚ä¹‹åä½¿ç”¨ BatchNorm
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(32)
        self.fc1 = nn.Linear(32 * 8 * 8, 10)
        self.bn_fc = nn.BatchNorm1d(10)  # åœ¨å…¨è¿æ¥å±‚ä¹‹åä½¿ç”¨ BatchNorm1d

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = torch.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = torch.relu(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = self.bn_fc(x)
        return x

# åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
model = SimpleCNN()
input_data = torch.randn(4, 3, 8, 8)  # å‡è®¾æœ‰ 4 å¼  RGB å›¾åƒ

# å‰å‘ä¼ æ’­
output = model(input_data)
print(output.shape)  # è¾“å‡º: torch.Size([4, 10])
```

åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œ`BatchNorm` ä¼šè®¡ç®—å½“å‰ batch çš„å‡å€¼å’Œæ–¹å·®ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ã€‚

åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼ˆ`model.eval()`ï¼‰ï¼Œ`BatchNorm` ä¼šä½¿ç”¨æ•´ä¸ªè®­ç»ƒé›†çš„ç»Ÿè®¡å‡å€¼å’Œæ–¹å·®ï¼ˆé€šè¿‡æ»‘åŠ¨å¹³å‡è®¡ç®—ï¼‰ï¼Œè€Œä¸æ˜¯å½“å‰ batch çš„ç»Ÿè®¡é‡ã€‚ 

### 6.2 Layer Normalization

è¾“å…¥`(batch_size, seq_len, d_model)`ï¼Œå¯¹äºæ¯ä¸ªä½ç½®ï¼ˆæ¯ä¸ª `batch_size` å’Œ `seq_len` å¯¹åº”çš„å…ƒç´ ï¼‰ï¼ŒLayer Normalization ä¼šè®¡ç®—**è¯¥ä½ç½®æ‰€æœ‰ç‰¹å¾ç»´åº¦çš„å‡å€¼å’Œæ–¹å·®**ã€‚

```python
import torch
import torch.nn as nn

# å®šä¹‰ LayerNorm å±‚
d_model = 256
layer_norm = nn.LayerNorm(d_model)

# åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º (batch_size, seq_len, d_model) çš„è¾“å…¥
input_data = torch.randn(32, 50, d_model)  # å‡è®¾ batch_size=32ï¼Œåºåˆ—é•¿åº¦ seq_len=50

# ä½¿ç”¨ LayerNorm å½’ä¸€åŒ–
output_data = layer_norm(input_data)
print(output_data.shape)  # è¾“å‡º: torch.Size([32, 50, 256])
```

